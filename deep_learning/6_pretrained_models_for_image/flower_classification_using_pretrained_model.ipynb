{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7iz4ivIW4rag"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZR6C5aREz9x"
      },
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbXUCx78_8wx"
      },
      "source": [
        "##**1. Load Flower dataset and Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDNl57--Auyv"
      },
      "source": [
        "**Load Dataset from Path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DIuxfkko5E4y"
      },
      "outputs": [],
      "source": [
        "data_pạth = \"data/flower_photos\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ogcAcqEZ6nzR"
      },
      "outputs": [],
      "source": [
        "# load image from path\n",
        "dataset = datasets.ImageFolder(root=data_pạth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dORKXFMGRgZ",
        "outputId": "2e67d30d-5339-4a7b-a89b-7ebcfc213ea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 3670\n",
              "    Root location: data/flower_photos"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOXNzbH1AqQE",
        "outputId": "5ca678fe-988a-4696-f3f4-306b6766d38a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_samples = len(dataset)\n",
        "num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyYTDHMu5RO_",
        "outputId": "35dc8177-b662-4f93-85c7-9022522ab638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QLwg4Lz4JdSb"
      },
      "outputs": [],
      "source": [
        "num_classes = len(dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk4JU_zJAyu9"
      },
      "source": [
        "**Training : validation : testing = 0.8 : 0.1 : 0.1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "coCip7FO5qEZ"
      },
      "outputs": [],
      "source": [
        "TRAIN_RATIO, VALID_RATIO = 0.8, 0.1\n",
        "\n",
        "n_train_examples = int(num_samples * TRAIN_RATIO)\n",
        "n_valid_examples = int(num_samples * VALID_RATIO)\n",
        "n_test_examples = num_samples - n_train_examples - n_valid_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xnoMF6b555D",
        "outputId": "456ce1bb-92b0-47fc-ffcb-e543d4a50a37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2936, 367, 367)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_train_examples, n_valid_examples, n_test_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r1CXDmD75-oE"
      },
      "outputs": [],
      "source": [
        "train_dataset, valid_dataset, test_dataset = data.random_split(\n",
        "    dataset,\n",
        "    [n_train_examples, n_valid_examples, n_test_examples]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NxVOeh-Bvqm"
      },
      "source": [
        "**Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iT1NCq8F9yf0"
      },
      "outputs": [],
      "source": [
        "# resize + convert to tensor\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fBXUGNG-6DzP"
      },
      "outputs": [],
      "source": [
        "train_dataset.dataset.transform = train_transforms\n",
        "valid_dataset.dataset.transform = test_transforms\n",
        "test_dataset.dataset.transform = test_transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##**2. Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ic0f7rl56aQB"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_dataloader = data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_dataloader = data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fYAs-lDO6e1J"
      },
      "outputs": [],
      "source": [
        "inputs, labels = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opplwv4CHfmg",
        "outputId": "f4fe17e5-bb15-4240-e0cd-76a06296ddff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4bpfz_7LdLs",
        "outputId": "588f5f19-98c1-4186-ae93-efb3bf5859f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uExLmvJKRS2"
      },
      "source": [
        "##**3. Trainer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gsTuucfWKTtE"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=5):\n",
        "    model.train()\n",
        "    accs, losses = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(inputs)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(predictions, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_acc = (predictions.argmax(1) == labels).sum().item()\n",
        "        acc = total_acc / labels.size(0)\n",
        "        accs.append(acc)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "                \"| accuracy {:8.3f}\".format(\n",
        "                    epoch, idx, len(train_dataloader), sum(accs) / len(accs)\n",
        "                )\n",
        "            )\n",
        "            start_time = time.time()\n",
        "\n",
        "    epoch_acc = sum(accs) / len(accs)\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X7kn_HbVKZyz"
      },
      "outputs": [],
      "source": [
        "def evaluate_epoch(model, criterion, valid_dataloader):\n",
        "    model.eval()\n",
        "    accs, losses = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(inputs)\n",
        "\n",
        "            loss = criterion(predictions, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            total_acc = (predictions.argmax(1) == labels).sum().item()\n",
        "            acc = total_acc / labels.size(0)\n",
        "            accs.append(acc)\n",
        "\n",
        "    epoch_acc = sum(accs) / len(accs)\n",
        "    epoch_loss = sum(losses) / len(losses)\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yLASx-6kM0Wg"
      },
      "outputs": [],
      "source": [
        "def train(model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device):\n",
        "    train_accs, train_losses = [], []\n",
        "    eval_accs, eval_losses = [], []\n",
        "    best_loss_eval = 100\n",
        "    times = []\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        # Training\n",
        "        train_acc, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n",
        "        train_accs.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Evaluation\n",
        "        eval_acc, eval_loss = evaluate_epoch(model, criterion, valid_dataloader)\n",
        "        eval_accs.append(eval_acc)\n",
        "        eval_losses.append(eval_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if eval_loss < best_loss_eval:\n",
        "            torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
        "\n",
        "        times.append(time.time() - epoch_start_time)\n",
        "        # Print loss, acc end epoch\n",
        "        print(\"-\" * 59)\n",
        "        print(\n",
        "            \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
        "            \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
        "                epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
        "            )\n",
        "        )\n",
        "        print(\"-\" * 59)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
        "    model.eval()\n",
        "    metrics = {\n",
        "        'train_accuracy': train_accs,\n",
        "        'train_loss': train_losses,\n",
        "        'valid_accuracy': eval_accs,\n",
        "        'valid_loss': eval_losses,\n",
        "        'time': times\n",
        "    }\n",
        "    return model, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dx2itK1p2kMu"
      },
      "outputs": [],
      "source": [
        "def plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses):\n",
        "    epochs = list(range(num_epochs))\n",
        "    fig, axs = plt.subplots(nrows = 1, ncols =2 , figsize = (12,6))\n",
        "    axs[0].plot(epochs, train_accs, label = \"Training\")\n",
        "    axs[0].plot(epochs, eval_accs, label = \"Evaluation\")\n",
        "    axs[1].plot(epochs, train_losses, label = \"Training\")\n",
        "    axs[1].plot(epochs, eval_losses, label = \"Evaluation\")\n",
        "    axs[0].set_xlabel(\"Epochs\")\n",
        "    axs[1].set_xlabel(\"Epochs\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V13mwIfHIDFj"
      },
      "source": [
        "##**4. Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ9jpdtYIQQt"
      },
      "source": [
        "###**4.1. From Scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xCTI-HbEIV22"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(weights=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cvNkDYxgJOW2"
      },
      "outputs": [],
      "source": [
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxQg-wbOJKAl",
        "outputId": "d31fff58-abf8-4673-ea6e-ad38ea5bb280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v7c1hN4XKlOz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40tNVygtLtUF",
        "outputId": "baa4bb1e-0a65-47c3-b569-ff598e3f1c75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_niEdzJoGq",
        "outputId": "04817d8a-d575-4201-c0fa-37bf840f38ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 5]           2,565\n",
            "================================================================\n",
            "Total params: 11,179,077\n",
            "Trainable params: 11,179,077\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OWcqI7AqJ3gT"
      },
      "outputs": [],
      "source": [
        "predictions = model(inputs.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEvVLZECJ7DB",
        "outputId": "238f04a5-0053-4a9a-fac2-6d473edebda5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bl_FATGAKfQS"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZqmiXtfKiKB",
        "outputId": "1a6b40a5-e1e8-455b-d5e5-54818ed97c3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.6445, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = criterion(predictions, labels.to(device))\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdBjCDa9Kn6k",
        "outputId": "098defce-aad7-4a2b-c53c-aeea8f83806f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   0 |     5/   46 batches | accuracy    0.362\n",
            "| epoch   0 |    10/   46 batches | accuracy    0.435\n",
            "| epoch   0 |    15/   46 batches | accuracy    0.465\n",
            "| epoch   0 |    20/   46 batches | accuracy    0.488\n",
            "| epoch   0 |    25/   46 batches | accuracy    0.498\n",
            "| epoch   0 |    30/   46 batches | accuracy    0.504\n",
            "| epoch   0 |    35/   46 batches | accuracy    0.509\n",
            "| epoch   0 |    40/   46 batches | accuracy    0.516\n",
            "| epoch   0 |    45/   46 batches | accuracy    0.522\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.521884704968944, 1.2461121846800265)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_acc, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
        "train_acc, train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIk3fO3Knh0q",
        "outputId": "811ffdaf-f977-4d02-d977-e285ef588de0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5043772163120567, 1.399165411790212)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_acc, eval_loss = evaluate_epoch(model, criterion, valid_dataloader)\n",
        "eval_acc, eval_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTOOGmnWipOH",
        "outputId": "1934bb72-2562-486a-f32b-5d728b2c7bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |     5/   46 batches | accuracy    0.341\n",
            "| epoch   1 |    10/   46 batches | accuracy    0.430\n",
            "| epoch   1 |    15/   46 batches | accuracy    0.449\n",
            "| epoch   1 |    20/   46 batches | accuracy    0.484\n",
            "| epoch   1 |    25/   46 batches | accuracy    0.499\n",
            "| epoch   1 |    30/   46 batches | accuracy    0.519\n",
            "| epoch   1 |    35/   46 batches | accuracy    0.529\n",
            "| epoch   1 |    40/   46 batches | accuracy    0.539\n",
            "| epoch   1 |    45/   46 batches | accuracy    0.547\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   1 | Time: 26.34s | Train Accuracy    0.547 | Train Loss    1.109 | Valid Accuracy    0.559 | Valid Loss    1.155 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |     5/   46 batches | accuracy    0.656\n",
            "| epoch   2 |    10/   46 batches | accuracy    0.669\n",
            "| epoch   2 |    15/   46 batches | accuracy    0.685\n",
            "| epoch   2 |    20/   46 batches | accuracy    0.688\n",
            "| epoch   2 |    25/   46 batches | accuracy    0.693\n",
            "| epoch   2 |    30/   46 batches | accuracy    0.695\n",
            "| epoch   2 |    35/   46 batches | accuracy    0.695\n",
            "| epoch   2 |    40/   46 batches | accuracy    0.700\n",
            "| epoch   2 |    45/   46 batches | accuracy    0.702\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   2 | Time: 26.45s | Train Accuracy    0.702 | Train Loss    0.804 | Valid Accuracy    0.590 | Valid Loss    1.200 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |     5/   46 batches | accuracy    0.823\n",
            "| epoch   3 |    10/   46 batches | accuracy    0.822\n",
            "| epoch   3 |    15/   46 batches | accuracy    0.806\n",
            "| epoch   3 |    20/   46 batches | accuracy    0.806\n",
            "| epoch   3 |    25/   46 batches | accuracy    0.800\n",
            "| epoch   3 |    30/   46 batches | accuracy    0.797\n",
            "| epoch   3 |    35/   46 batches | accuracy    0.794\n",
            "| epoch   3 |    40/   46 batches | accuracy    0.789\n",
            "| epoch   3 |    45/   46 batches | accuracy    0.789\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   3 | Time: 27.23s | Train Accuracy    0.789 | Train Loss    0.596 | Valid Accuracy    0.327 | Valid Loss    2.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |     5/   46 batches | accuracy    0.857\n",
            "| epoch   4 |    10/   46 batches | accuracy    0.859\n",
            "| epoch   4 |    15/   46 batches | accuracy    0.854\n",
            "| epoch   4 |    20/   46 batches | accuracy    0.860\n",
            "| epoch   4 |    25/   46 batches | accuracy    0.856\n",
            "| epoch   4 |    30/   46 batches | accuracy    0.861\n",
            "| epoch   4 |    35/   46 batches | accuracy    0.867\n",
            "| epoch   4 |    40/   46 batches | accuracy    0.868\n",
            "| epoch   4 |    45/   46 batches | accuracy    0.864\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   4 | Time: 27.46s | Train Accuracy    0.864 | Train Loss    0.412 | Valid Accuracy    0.518 | Valid Loss    1.387 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |     5/   46 batches | accuracy    0.935\n",
            "| epoch   5 |    10/   46 batches | accuracy    0.940\n",
            "| epoch   5 |    15/   46 batches | accuracy    0.950\n",
            "| epoch   5 |    20/   46 batches | accuracy    0.952\n",
            "| epoch   5 |    25/   46 batches | accuracy    0.954\n",
            "| epoch   5 |    30/   46 batches | accuracy    0.956\n",
            "| epoch   5 |    35/   46 batches | accuracy    0.953\n",
            "| epoch   5 |    40/   46 batches | accuracy    0.952\n",
            "| epoch   5 |    45/   46 batches | accuracy    0.951\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   5 | Time: 27.32s | Train Accuracy    0.951 | Train Loss    0.190 | Valid Accuracy    0.592 | Valid Loss    1.397 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |     5/   46 batches | accuracy    0.971\n",
            "| epoch   6 |    10/   46 batches | accuracy    0.969\n",
            "| epoch   6 |    15/   46 batches | accuracy    0.973\n",
            "| epoch   6 |    20/   46 batches | accuracy    0.972\n",
            "| epoch   6 |    25/   46 batches | accuracy    0.973\n",
            "| epoch   6 |    30/   46 batches | accuracy    0.973\n",
            "| epoch   6 |    35/   46 batches | accuracy    0.973\n",
            "| epoch   6 |    40/   46 batches | accuracy    0.972\n",
            "| epoch   6 |    45/   46 batches | accuracy    0.974\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   6 | Time: 27.31s | Train Accuracy    0.974 | Train Loss    0.104 | Valid Accuracy    0.543 | Valid Loss    1.571 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |     5/   46 batches | accuracy    0.990\n",
            "| epoch   7 |    10/   46 batches | accuracy    0.983\n",
            "| epoch   7 |    15/   46 batches | accuracy    0.987\n",
            "| epoch   7 |    20/   46 batches | accuracy    0.988\n",
            "| epoch   7 |    25/   46 batches | accuracy    0.990\n",
            "| epoch   7 |    30/   46 batches | accuracy    0.990\n",
            "| epoch   7 |    35/   46 batches | accuracy    0.990\n",
            "| epoch   7 |    40/   46 batches | accuracy    0.990\n",
            "| epoch   7 |    45/   46 batches | accuracy    0.990\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   7 | Time: 27.41s | Train Accuracy    0.990 | Train Loss    0.051 | Valid Accuracy    0.702 | Valid Loss    1.060 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |     5/   46 batches | accuracy    0.997\n",
            "| epoch   8 |    10/   46 batches | accuracy    0.997\n",
            "| epoch   8 |    15/   46 batches | accuracy    0.998\n",
            "| epoch   8 |    20/   46 batches | accuracy    0.996\n",
            "| epoch   8 |    25/   46 batches | accuracy    0.996\n",
            "| epoch   8 |    30/   46 batches | accuracy    0.995\n",
            "| epoch   8 |    35/   46 batches | accuracy    0.996\n",
            "| epoch   8 |    40/   46 batches | accuracy    0.996\n",
            "| epoch   8 |    45/   46 batches | accuracy    0.996\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   8 | Time: 27.06s | Train Accuracy    0.996 | Train Loss    0.028 | Valid Accuracy    0.680 | Valid Loss    1.133 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |     5/   46 batches | accuracy    0.997\n",
            "| epoch   9 |    10/   46 batches | accuracy    0.996\n",
            "| epoch   9 |    15/   46 batches | accuracy    0.996\n",
            "| epoch   9 |    20/   46 batches | accuracy    0.997\n",
            "| epoch   9 |    25/   46 batches | accuracy    0.998\n",
            "| epoch   9 |    30/   46 batches | accuracy    0.997\n",
            "| epoch   9 |    35/   46 batches | accuracy    0.998\n",
            "| epoch   9 |    40/   46 batches | accuracy    0.998\n",
            "| epoch   9 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   9 | Time: 27.53s | Train Accuracy    0.998 | Train Loss    0.015 | Valid Accuracy    0.704 | Valid Loss    1.001 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  10 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  10 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  10 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  10 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  10 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  10 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  10 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  10 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  10 | Time: 26.62s | Train Accuracy    0.998 | Train Loss    0.013 | Valid Accuracy    0.676 | Valid Loss    1.077 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  11 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  11 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  11 |    20/   46 batches | accuracy    0.998\n",
            "| epoch  11 |    25/   46 batches | accuracy    0.997\n",
            "| epoch  11 |    30/   46 batches | accuracy    0.997\n",
            "| epoch  11 |    35/   46 batches | accuracy    0.997\n",
            "| epoch  11 |    40/   46 batches | accuracy    0.997\n",
            "| epoch  11 |    45/   46 batches | accuracy    0.997\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  11 | Time: 26.78s | Train Accuracy    0.997 | Train Loss    0.022 | Valid Accuracy    0.671 | Valid Loss    1.261 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  12 |    10/   46 batches | accuracy    0.997\n",
            "| epoch  12 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  12 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  12 |    25/   46 batches | accuracy    0.998\n",
            "| epoch  12 |    30/   46 batches | accuracy    0.998\n",
            "| epoch  12 |    35/   46 batches | accuracy    0.998\n",
            "| epoch  12 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  12 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  12 | Time: 26.64s | Train Accuracy    0.998 | Train Loss    0.014 | Valid Accuracy    0.631 | Valid Loss    1.357 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  13 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  13 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  13 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  13 |    25/   46 batches | accuracy    0.998\n",
            "| epoch  13 |    30/   46 batches | accuracy    0.998\n",
            "| epoch  13 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  13 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  13 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  13 | Time: 28.57s | Train Accuracy    0.998 | Train Loss    0.013 | Valid Accuracy    0.697 | Valid Loss    1.096 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  14 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  14 |    15/   46 batches | accuracy    0.997\n",
            "| epoch  14 |    20/   46 batches | accuracy    0.998\n",
            "| epoch  14 |    25/   46 batches | accuracy    0.998\n",
            "| epoch  14 |    30/   46 batches | accuracy    0.998\n",
            "| epoch  14 |    35/   46 batches | accuracy    0.998\n",
            "| epoch  14 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  14 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  14 | Time: 27.55s | Train Accuracy    0.998 | Train Loss    0.010 | Valid Accuracy    0.623 | Valid Loss    1.421 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  15 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  15 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  15 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  15 | Time: 28.51s | Train Accuracy    0.998 | Train Loss    0.011 | Valid Accuracy    0.636 | Valid Loss    1.537 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  16 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  16 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  16 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  16 | Time: 28.61s | Train Accuracy    0.999 | Train Loss    0.007 | Valid Accuracy    0.717 | Valid Loss    1.087 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  17 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  17 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  17 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  17 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  17 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  17 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  17 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  17 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  17 | Time: 27.35s | Train Accuracy    1.000 | Train Loss    0.005 | Valid Accuracy    0.670 | Valid Loss    1.203 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  18 |    10/   46 batches | accuracy    0.997\n",
            "| epoch  18 |    15/   46 batches | accuracy    0.997\n",
            "| epoch  18 |    20/   46 batches | accuracy    0.996\n",
            "| epoch  18 |    25/   46 batches | accuracy    0.996\n",
            "| epoch  18 |    30/   46 batches | accuracy    0.996\n",
            "| epoch  18 |    35/   46 batches | accuracy    0.994\n",
            "| epoch  18 |    40/   46 batches | accuracy    0.992\n",
            "| epoch  18 |    45/   46 batches | accuracy    0.990\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  18 | Time: 27.39s | Train Accuracy    0.990 | Train Loss    0.036 | Valid Accuracy    0.631 | Valid Loss    1.995 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |     5/   46 batches | accuracy    0.974\n",
            "| epoch  19 |    10/   46 batches | accuracy    0.972\n",
            "| epoch  19 |    15/   46 batches | accuracy    0.969\n",
            "| epoch  19 |    20/   46 batches | accuracy    0.972\n",
            "| epoch  19 |    25/   46 batches | accuracy    0.971\n",
            "| epoch  19 |    30/   46 batches | accuracy    0.973\n",
            "| epoch  19 |    35/   46 batches | accuracy    0.973\n",
            "| epoch  19 |    40/   46 batches | accuracy    0.970\n",
            "| epoch  19 |    45/   46 batches | accuracy    0.970\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  19 | Time: 27.02s | Train Accuracy    0.970 | Train Loss    0.093 | Valid Accuracy    0.603 | Valid Loss    1.893 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |     5/   46 batches | accuracy    0.969\n",
            "| epoch  20 |    10/   46 batches | accuracy    0.970\n",
            "| epoch  20 |    15/   46 batches | accuracy    0.967\n",
            "| epoch  20 |    20/   46 batches | accuracy    0.966\n",
            "| epoch  20 |    25/   46 batches | accuracy    0.962\n",
            "| epoch  20 |    30/   46 batches | accuracy    0.963\n",
            "| epoch  20 |    35/   46 batches | accuracy    0.962\n",
            "| epoch  20 |    40/   46 batches | accuracy    0.963\n",
            "| epoch  20 |    45/   46 batches | accuracy    0.960\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  20 | Time: 27.12s | Train Accuracy    0.960 | Train Loss    0.125 | Valid Accuracy    0.400 | Valid Loss    2.966 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |     5/   46 batches | accuracy    0.951\n",
            "| epoch  21 |    10/   46 batches | accuracy    0.949\n",
            "| epoch  21 |    15/   46 batches | accuracy    0.961\n",
            "| epoch  21 |    20/   46 batches | accuracy    0.962\n",
            "| epoch  21 |    25/   46 batches | accuracy    0.963\n",
            "| epoch  21 |    30/   46 batches | accuracy    0.963\n",
            "| epoch  21 |    35/   46 batches | accuracy    0.963\n",
            "| epoch  21 |    40/   46 batches | accuracy    0.963\n",
            "| epoch  21 |    45/   46 batches | accuracy    0.964\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  21 | Time: 27.03s | Train Accuracy    0.964 | Train Loss    0.114 | Valid Accuracy    0.568 | Valid Loss    1.815 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |     5/   46 batches | accuracy    0.990\n",
            "| epoch  22 |    10/   46 batches | accuracy    0.986\n",
            "| epoch  22 |    15/   46 batches | accuracy    0.986\n",
            "| epoch  22 |    20/   46 batches | accuracy    0.986\n",
            "| epoch  22 |    25/   46 batches | accuracy    0.985\n",
            "| epoch  22 |    30/   46 batches | accuracy    0.984\n",
            "| epoch  22 |    35/   46 batches | accuracy    0.986\n",
            "| epoch  22 |    40/   46 batches | accuracy    0.985\n",
            "| epoch  22 |    45/   46 batches | accuracy    0.986\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  22 | Time: 26.88s | Train Accuracy    0.986 | Train Loss    0.054 | Valid Accuracy    0.593 | Valid Loss    1.704 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |     5/   46 batches | accuracy    0.995\n",
            "| epoch  23 |    10/   46 batches | accuracy    0.993\n",
            "| epoch  23 |    15/   46 batches | accuracy    0.991\n",
            "| epoch  23 |    20/   46 batches | accuracy    0.993\n",
            "| epoch  23 |    25/   46 batches | accuracy    0.994\n",
            "| epoch  23 |    30/   46 batches | accuracy    0.995\n",
            "| epoch  23 |    35/   46 batches | accuracy    0.996\n",
            "| epoch  23 |    40/   46 batches | accuracy    0.996\n",
            "| epoch  23 |    45/   46 batches | accuracy    0.996\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  23 | Time: 27.12s | Train Accuracy    0.996 | Train Loss    0.021 | Valid Accuracy    0.663 | Valid Loss    1.274 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  24 |    10/   46 batches | accuracy    0.997\n",
            "| epoch  24 |    15/   46 batches | accuracy    0.997\n",
            "| epoch  24 |    20/   46 batches | accuracy    0.998\n",
            "| epoch  24 |    25/   46 batches | accuracy    0.997\n",
            "| epoch  24 |    30/   46 batches | accuracy    0.997\n",
            "| epoch  24 |    35/   46 batches | accuracy    0.998\n",
            "| epoch  24 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  24 |    45/   46 batches | accuracy    0.997\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  24 | Time: 27.26s | Train Accuracy    0.997 | Train Loss    0.013 | Valid Accuracy    0.669 | Valid Loss    1.272 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  25 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  25 |    15/   46 batches | accuracy    0.997\n",
            "| epoch  25 |    20/   46 batches | accuracy    0.998\n",
            "| epoch  25 |    25/   46 batches | accuracy    0.998\n",
            "| epoch  25 |    30/   46 batches | accuracy    0.997\n",
            "| epoch  25 |    35/   46 batches | accuracy    0.998\n",
            "| epoch  25 |    40/   46 batches | accuracy    0.998\n",
            "| epoch  25 |    45/   46 batches | accuracy    0.998\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  25 | Time: 28.16s | Train Accuracy    0.998 | Train Loss    0.012 | Valid Accuracy    0.666 | Valid Loss    1.433 \n",
            "-----------------------------------------------------------\n",
            "| epoch  26 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  26 |    10/   46 batches | accuracy    0.997\n",
            "| epoch  26 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  26 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  26 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  26 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  26 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  26 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  26 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  26 | Time: 27.12s | Train Accuracy    0.999 | Train Loss    0.005 | Valid Accuracy    0.667 | Valid Loss    1.248 \n",
            "-----------------------------------------------------------\n",
            "| epoch  27 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  27 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  27 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  27 | Time: 27.01s | Train Accuracy    1.000 | Train Loss    0.004 | Valid Accuracy    0.685 | Valid Loss    1.183 \n",
            "-----------------------------------------------------------\n",
            "| epoch  28 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  28 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  28 | Time: 27.68s | Train Accuracy    1.000 | Train Loss    0.003 | Valid Accuracy    0.688 | Valid Loss    1.196 \n",
            "-----------------------------------------------------------\n",
            "| epoch  29 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  29 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  29 | Time: 27.35s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.682 | Valid Loss    1.211 \n",
            "-----------------------------------------------------------\n",
            "| epoch  30 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  30 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  30 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  30 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  30 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  30 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  30 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  30 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  30 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  30 | Time: 27.78s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.687 | Valid Loss    1.189 \n",
            "-----------------------------------------------------------\n",
            "| epoch  31 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  31 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  31 | Time: 27.40s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.697 | Valid Loss    1.197 \n",
            "-----------------------------------------------------------\n",
            "| epoch  32 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  32 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  32 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  32 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  32 | Time: 27.61s | Train Accuracy    0.999 | Train Loss    0.002 | Valid Accuracy    0.703 | Valid Loss    1.191 \n",
            "-----------------------------------------------------------\n",
            "| epoch  33 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  33 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  33 | Time: 27.59s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.694 | Valid Loss    1.183 \n",
            "-----------------------------------------------------------\n",
            "| epoch  34 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  34 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  34 | Time: 27.46s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.690 | Valid Loss    1.184 \n",
            "-----------------------------------------------------------\n",
            "| epoch  35 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  35 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  35 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  35 | Time: 27.32s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.694 | Valid Loss    1.186 \n",
            "-----------------------------------------------------------\n",
            "| epoch  36 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  36 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  36 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  36 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  36 | Time: 27.03s | Train Accuracy    0.999 | Train Loss    0.002 | Valid Accuracy    0.690 | Valid Loss    1.191 \n",
            "-----------------------------------------------------------\n",
            "| epoch  37 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  37 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  37 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  37 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  37 | Time: 27.17s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.691 | Valid Loss    1.202 \n",
            "-----------------------------------------------------------\n",
            "| epoch  38 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  38 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  38 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  38 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  38 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  38 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  38 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  38 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  38 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  38 | Time: 27.38s | Train Accuracy    1.000 | Train Loss    0.002 | Valid Accuracy    0.703 | Valid Loss    1.178 \n",
            "-----------------------------------------------------------\n",
            "| epoch  39 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  39 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  39 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  39 | Time: 26.77s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.700 | Valid Loss    1.194 \n",
            "-----------------------------------------------------------\n",
            "| epoch  40 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  40 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  40 | Time: 27.04s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.705 | Valid Loss    1.198 \n",
            "-----------------------------------------------------------\n",
            "| epoch  41 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  41 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  41 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  41 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  41 | Time: 26.67s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.706 | Valid Loss    1.193 \n",
            "-----------------------------------------------------------\n",
            "| epoch  42 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  42 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  42 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  42 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  42 | Time: 26.98s | Train Accuracy    0.999 | Train Loss    0.002 | Valid Accuracy    0.700 | Valid Loss    1.199 \n",
            "-----------------------------------------------------------\n",
            "| epoch  43 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  43 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  43 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  43 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  43 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  43 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  43 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  43 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  43 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  43 | Time: 27.66s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.697 | Valid Loss    1.203 \n",
            "-----------------------------------------------------------\n",
            "| epoch  44 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  44 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  44 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  44 | Time: 26.92s | Train Accuracy    0.999 | Train Loss    0.001 | Valid Accuracy    0.707 | Valid Loss    1.183 \n",
            "-----------------------------------------------------------\n",
            "| epoch  45 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  45 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  45 | Time: 126.34s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.698 | Valid Loss    1.205 \n",
            "-----------------------------------------------------------\n",
            "| epoch  46 |     5/   46 batches | accuracy    0.997\n",
            "| epoch  46 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    15/   46 batches | accuracy    0.998\n",
            "| epoch  46 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    35/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    40/   46 batches | accuracy    0.999\n",
            "| epoch  46 |    45/   46 batches | accuracy    0.999\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  46 | Time: 232.17s | Train Accuracy    0.999 | Train Loss    0.001 | Valid Accuracy    0.708 | Valid Loss    1.198 \n",
            "-----------------------------------------------------------\n",
            "| epoch  47 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  47 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  47 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  47 | Time: 231.73s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.697 | Valid Loss    1.191 \n",
            "-----------------------------------------------------------\n",
            "| epoch  48 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  48 |    10/   46 batches | accuracy    0.999\n",
            "| epoch  48 |    15/   46 batches | accuracy    0.999\n",
            "| epoch  48 |    20/   46 batches | accuracy    0.999\n",
            "| epoch  48 |    25/   46 batches | accuracy    0.999\n",
            "| epoch  48 |    30/   46 batches | accuracy    0.999\n",
            "| epoch  48 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  48 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  48 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  48 | Time: 232.07s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.699 | Valid Loss    1.214 \n",
            "-----------------------------------------------------------\n",
            "| epoch  49 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  49 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  49 | Time: 231.48s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.703 | Valid Loss    1.204 \n",
            "-----------------------------------------------------------\n",
            "| epoch  50 |     5/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    10/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    15/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    20/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    25/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    30/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    35/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    40/   46 batches | accuracy    1.000\n",
            "| epoch  50 |    45/   46 batches | accuracy    1.000\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  50 | Time: 232.97s | Train Accuracy    1.000 | Train Loss    0.001 | Valid Accuracy    0.705 | Valid Loss    1.201 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "base_model = models.resnet18(weights=None)\n",
        "in_features = base_model.fc.in_features\n",
        "base_model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "base_model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(base_model.parameters(), lr=0.0001)\n",
        "\n",
        "num_epochs = 50\n",
        "save_model = 'model'\n",
        "os.makedirs(save_model, exist_ok = True)\n",
        "model_name = 'base_model'\n",
        "\n",
        "base_model, base_metrics = train(\n",
        "    base_model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv_PC15esm56",
        "outputId": "d18f1c49-4fcc-4d3a-f41b-694d34b351bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7585882092198583, 1.0438550511995952)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_acc, test_loss = evaluate_epoch(base_model, criterion, test_dataloader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "icYRUvp22gV3",
        "outputId": "5f12479c-d507-4160-9973-d3515b08649f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_result(\n",
        "    num_epochs,\n",
        "    base_metrics[\"train_accuracy\"],\n",
        "    base_metrics[\"valid_accuracy\"],\n",
        "    base_metrics[\"train_loss\"],\n",
        "    base_metrics[\"valid_loss\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v0AnriF2shS"
      },
      "source": [
        "###**4.2.Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0R2Q9qZ2wcL",
        "outputId": "a3db1caf-f574-43c1-e954-6b6b8b3169e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/huydn/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:12<00:00, 3.66MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdywOdZ73Mkk",
        "outputId": "1286b3e0-0954-4fbd-afc4-4636d4ca247f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PT-JtF5i3Vj-"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "   param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WyPOMN8B3Y2O"
      },
      "outputs": [],
      "source": [
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1mijCVS3d_R",
        "outputId": "8043a6f0-2fc8-4d4a-a6a0-71d749a67fe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXlI7QhR3jHK",
        "outputId": "c01ad5fb-e86f-4692-c22d-142edc63437d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IELmhrt3hVv",
        "outputId": "3e8c5bc8-3279-42ef-871f-5fbe8a3fd3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 5]           2,565\n",
            "================================================================\n",
            "Total params: 11,179,077\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 11,176,512\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFgsbs2k4mhN",
        "outputId": "75a5d423-9cb1-4f6e-f2d3-67af7dc5a6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |     5/   46 batches | accuracy    0.245\n",
            "| epoch   1 |    10/   46 batches | accuracy    0.254\n",
            "| epoch   1 |    15/   46 batches | accuracy    0.264\n",
            "| epoch   1 |    20/   46 batches | accuracy    0.284\n",
            "| epoch   1 |    25/   46 batches | accuracy    0.299\n",
            "| epoch   1 |    30/   46 batches | accuracy    0.317\n",
            "| epoch   1 |    35/   46 batches | accuracy    0.324\n",
            "| epoch   1 |    40/   46 batches | accuracy    0.336\n",
            "| epoch   1 |    45/   46 batches | accuracy    0.350\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   1 | Time: 91.97s | Train Accuracy    0.350 | Train Loss    1.514 | Valid Accuracy    0.413 | Valid Loss    1.389 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |     5/   46 batches | accuracy    0.443\n",
            "| epoch   2 |    10/   46 batches | accuracy    0.496\n",
            "| epoch   2 |    15/   46 batches | accuracy    0.514\n",
            "| epoch   2 |    20/   46 batches | accuracy    0.519\n",
            "| epoch   2 |    25/   46 batches | accuracy    0.523\n",
            "| epoch   2 |    30/   46 batches | accuracy    0.523\n",
            "| epoch   2 |    35/   46 batches | accuracy    0.529\n",
            "| epoch   2 |    40/   46 batches | accuracy    0.538\n",
            "| epoch   2 |    45/   46 batches | accuracy    0.540\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   2 | Time: 90.38s | Train Accuracy    0.540 | Train Loss    1.295 | Valid Accuracy    0.592 | Valid Loss    1.197 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |     5/   46 batches | accuracy    0.607\n",
            "| epoch   3 |    10/   46 batches | accuracy    0.604\n",
            "| epoch   3 |    15/   46 batches | accuracy    0.624\n",
            "| epoch   3 |    20/   46 batches | accuracy    0.625\n",
            "| epoch   3 |    25/   46 batches | accuracy    0.635\n",
            "| epoch   3 |    30/   46 batches | accuracy    0.644\n",
            "| epoch   3 |    35/   46 batches | accuracy    0.646\n",
            "| epoch   3 |    40/   46 batches | accuracy    0.652\n",
            "| epoch   3 |    45/   46 batches | accuracy    0.659\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   3 | Time: 91.90s | Train Accuracy    0.659 | Train Loss    1.134 | Valid Accuracy    0.711 | Valid Loss    1.043 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |     5/   46 batches | accuracy    0.698\n",
            "| epoch   4 |    10/   46 batches | accuracy    0.695\n",
            "| epoch   4 |    15/   46 batches | accuracy    0.710\n",
            "| epoch   4 |    20/   46 batches | accuracy    0.714\n",
            "| epoch   4 |    25/   46 batches | accuracy    0.713\n",
            "| epoch   4 |    30/   46 batches | accuracy    0.715\n",
            "| epoch   4 |    35/   46 batches | accuracy    0.714\n",
            "| epoch   4 |    40/   46 batches | accuracy    0.720\n",
            "| epoch   4 |    45/   46 batches | accuracy    0.724\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   4 | Time: 90.94s | Train Accuracy    0.724 | Train Loss    1.006 | Valid Accuracy    0.770 | Valid Loss    0.924 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |     5/   46 batches | accuracy    0.750\n",
            "| epoch   5 |    10/   46 batches | accuracy    0.736\n",
            "| epoch   5 |    15/   46 batches | accuracy    0.750\n",
            "| epoch   5 |    20/   46 batches | accuracy    0.746\n",
            "| epoch   5 |    25/   46 batches | accuracy    0.748\n",
            "| epoch   5 |    30/   46 batches | accuracy    0.752\n",
            "| epoch   5 |    35/   46 batches | accuracy    0.756\n",
            "| epoch   5 |    40/   46 batches | accuracy    0.760\n",
            "| epoch   5 |    45/   46 batches | accuracy    0.763\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   5 | Time: 91.16s | Train Accuracy    0.763 | Train Loss    0.910 | Valid Accuracy    0.809 | Valid Loss    0.839 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |     5/   46 batches | accuracy    0.773\n",
            "| epoch   6 |    10/   46 batches | accuracy    0.781\n",
            "| epoch   6 |    15/   46 batches | accuracy    0.777\n",
            "| epoch   6 |    20/   46 batches | accuracy    0.780\n",
            "| epoch   6 |    25/   46 batches | accuracy    0.785\n",
            "| epoch   6 |    30/   46 batches | accuracy    0.782\n",
            "| epoch   6 |    35/   46 batches | accuracy    0.779\n",
            "| epoch   6 |    40/   46 batches | accuracy    0.781\n",
            "| epoch   6 |    45/   46 batches | accuracy    0.783\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   6 | Time: 90.22s | Train Accuracy    0.783 | Train Loss    0.836 | Valid Accuracy    0.816 | Valid Loss    0.779 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |     5/   46 batches | accuracy    0.786\n",
            "| epoch   7 |    10/   46 batches | accuracy    0.795\n",
            "| epoch   7 |    15/   46 batches | accuracy    0.798\n",
            "| epoch   7 |    20/   46 batches | accuracy    0.805\n",
            "| epoch   7 |    25/   46 batches | accuracy    0.805\n",
            "| epoch   7 |    30/   46 batches | accuracy    0.802\n",
            "| epoch   7 |    35/   46 batches | accuracy    0.808\n",
            "| epoch   7 |    40/   46 batches | accuracy    0.805\n",
            "| epoch   7 |    45/   46 batches | accuracy    0.800\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   7 | Time: 91.74s | Train Accuracy    0.800 | Train Loss    0.772 | Valid Accuracy    0.828 | Valid Loss    0.713 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |     5/   46 batches | accuracy    0.799\n",
            "| epoch   8 |    10/   46 batches | accuracy    0.810\n",
            "| epoch   8 |    15/   46 batches | accuracy    0.814\n",
            "| epoch   8 |    20/   46 batches | accuracy    0.810\n",
            "| epoch   8 |    25/   46 batches | accuracy    0.809\n",
            "| epoch   8 |    30/   46 batches | accuracy    0.809\n",
            "| epoch   8 |    35/   46 batches | accuracy    0.812\n",
            "| epoch   8 |    40/   46 batches | accuracy    0.811\n",
            "| epoch   8 |    45/   46 batches | accuracy    0.812\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   8 | Time: 94.01s | Train Accuracy    0.812 | Train Loss    0.729 | Valid Accuracy    0.856 | Valid Loss    0.669 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |     5/   46 batches | accuracy    0.839\n",
            "| epoch   9 |    10/   46 batches | accuracy    0.827\n",
            "| epoch   9 |    15/   46 batches | accuracy    0.829\n",
            "| epoch   9 |    20/   46 batches | accuracy    0.818\n",
            "| epoch   9 |    25/   46 batches | accuracy    0.813\n",
            "| epoch   9 |    30/   46 batches | accuracy    0.816\n",
            "| epoch   9 |    35/   46 batches | accuracy    0.815\n",
            "| epoch   9 |    40/   46 batches | accuracy    0.819\n",
            "| epoch   9 |    45/   46 batches | accuracy    0.818\n",
            "-----------------------------------------------------------\n",
            "| End of epoch   9 | Time: 91.47s | Train Accuracy    0.818 | Train Loss    0.684 | Valid Accuracy    0.857 | Valid Loss    0.625 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |     5/   46 batches | accuracy    0.818\n",
            "| epoch  10 |    10/   46 batches | accuracy    0.814\n",
            "| epoch  10 |    15/   46 batches | accuracy    0.820\n",
            "| epoch  10 |    20/   46 batches | accuracy    0.822\n",
            "| epoch  10 |    25/   46 batches | accuracy    0.819\n",
            "| epoch  10 |    30/   46 batches | accuracy    0.829\n",
            "| epoch  10 |    35/   46 batches | accuracy    0.829\n",
            "| epoch  10 |    40/   46 batches | accuracy    0.831\n",
            "| epoch  10 |    45/   46 batches | accuracy    0.830\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  10 | Time: 90.68s | Train Accuracy    0.830 | Train Loss    0.648 | Valid Accuracy    0.856 | Valid Loss    0.596 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |     5/   46 batches | accuracy    0.799\n",
            "| epoch  11 |    10/   46 batches | accuracy    0.835\n",
            "| epoch  11 |    15/   46 batches | accuracy    0.844\n",
            "| epoch  11 |    20/   46 batches | accuracy    0.841\n",
            "| epoch  11 |    25/   46 batches | accuracy    0.846\n",
            "| epoch  11 |    30/   46 batches | accuracy    0.840\n",
            "| epoch  11 |    35/   46 batches | accuracy    0.842\n",
            "| epoch  11 |    40/   46 batches | accuracy    0.842\n",
            "| epoch  11 |    45/   46 batches | accuracy    0.842\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  11 | Time: 93.87s | Train Accuracy    0.842 | Train Loss    0.614 | Valid Accuracy    0.873 | Valid Loss    0.569 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |     5/   46 batches | accuracy    0.831\n",
            "| epoch  12 |    10/   46 batches | accuracy    0.838\n",
            "| epoch  12 |    15/   46 batches | accuracy    0.837\n",
            "| epoch  12 |    20/   46 batches | accuracy    0.839\n",
            "| epoch  12 |    25/   46 batches | accuracy    0.832\n",
            "| epoch  12 |    30/   46 batches | accuracy    0.828\n",
            "| epoch  12 |    35/   46 batches | accuracy    0.834\n",
            "| epoch  12 |    40/   46 batches | accuracy    0.838\n",
            "| epoch  12 |    45/   46 batches | accuracy    0.841\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  12 | Time: 92.23s | Train Accuracy    0.841 | Train Loss    0.593 | Valid Accuracy    0.862 | Valid Loss    0.545 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |     5/   46 batches | accuracy    0.823\n",
            "| epoch  13 |    10/   46 batches | accuracy    0.841\n",
            "| epoch  13 |    15/   46 batches | accuracy    0.850\n",
            "| epoch  13 |    20/   46 batches | accuracy    0.844\n",
            "| epoch  13 |    25/   46 batches | accuracy    0.849\n",
            "| epoch  13 |    30/   46 batches | accuracy    0.849\n",
            "| epoch  13 |    35/   46 batches | accuracy    0.848\n",
            "| epoch  13 |    40/   46 batches | accuracy    0.845\n",
            "| epoch  13 |    45/   46 batches | accuracy    0.847\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  13 | Time: 92.18s | Train Accuracy    0.847 | Train Loss    0.569 | Valid Accuracy    0.875 | Valid Loss    0.526 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |     5/   46 batches | accuracy    0.844\n",
            "| epoch  14 |    10/   46 batches | accuracy    0.862\n",
            "| epoch  14 |    15/   46 batches | accuracy    0.853\n",
            "| epoch  14 |    20/   46 batches | accuracy    0.850\n",
            "| epoch  14 |    25/   46 batches | accuracy    0.848\n",
            "| epoch  14 |    30/   46 batches | accuracy    0.846\n",
            "| epoch  14 |    35/   46 batches | accuracy    0.845\n",
            "| epoch  14 |    40/   46 batches | accuracy    0.847\n",
            "| epoch  14 |    45/   46 batches | accuracy    0.850\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  14 | Time: 92.03s | Train Accuracy    0.850 | Train Loss    0.546 | Valid Accuracy    0.877 | Valid Loss    0.509 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |     5/   46 batches | accuracy    0.836\n",
            "| epoch  15 |    10/   46 batches | accuracy    0.841\n",
            "| epoch  15 |    15/   46 batches | accuracy    0.848\n",
            "| epoch  15 |    20/   46 batches | accuracy    0.856\n",
            "| epoch  15 |    25/   46 batches | accuracy    0.861\n",
            "| epoch  15 |    30/   46 batches | accuracy    0.861\n",
            "| epoch  15 |    35/   46 batches | accuracy    0.859\n",
            "| epoch  15 |    40/   46 batches | accuracy    0.857\n",
            "| epoch  15 |    45/   46 batches | accuracy    0.855\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  15 | Time: 95.42s | Train Accuracy    0.855 | Train Loss    0.531 | Valid Accuracy    0.869 | Valid Loss    0.491 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |     5/   46 batches | accuracy    0.857\n",
            "| epoch  16 |    10/   46 batches | accuracy    0.831\n",
            "| epoch  16 |    15/   46 batches | accuracy    0.843\n",
            "| epoch  16 |    20/   46 batches | accuracy    0.849\n",
            "| epoch  16 |    25/   46 batches | accuracy    0.847\n",
            "| epoch  16 |    30/   46 batches | accuracy    0.847\n",
            "| epoch  16 |    35/   46 batches | accuracy    0.847\n",
            "| epoch  16 |    40/   46 batches | accuracy    0.851\n",
            "| epoch  16 |    45/   46 batches | accuracy    0.851\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  16 | Time: 92.36s | Train Accuracy    0.851 | Train Loss    0.518 | Valid Accuracy    0.875 | Valid Loss    0.481 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |     5/   46 batches | accuracy    0.859\n",
            "| epoch  17 |    10/   46 batches | accuracy    0.862\n",
            "| epoch  17 |    15/   46 batches | accuracy    0.864\n",
            "| epoch  17 |    20/   46 batches | accuracy    0.870\n",
            "| epoch  17 |    25/   46 batches | accuracy    0.868\n",
            "| epoch  17 |    30/   46 batches | accuracy    0.871\n",
            "| epoch  17 |    35/   46 batches | accuracy    0.868\n",
            "| epoch  17 |    40/   46 batches | accuracy    0.869\n",
            "| epoch  17 |    45/   46 batches | accuracy    0.866\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  17 | Time: 92.86s | Train Accuracy    0.866 | Train Loss    0.499 | Valid Accuracy    0.880 | Valid Loss    0.467 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |     5/   46 batches | accuracy    0.872\n",
            "| epoch  18 |    10/   46 batches | accuracy    0.878\n",
            "| epoch  18 |    15/   46 batches | accuracy    0.874\n",
            "| epoch  18 |    20/   46 batches | accuracy    0.862\n",
            "| epoch  18 |    25/   46 batches | accuracy    0.863\n",
            "| epoch  18 |    30/   46 batches | accuracy    0.860\n",
            "| epoch  18 |    35/   46 batches | accuracy    0.860\n",
            "| epoch  18 |    40/   46 batches | accuracy    0.863\n",
            "| epoch  18 |    45/   46 batches | accuracy    0.861\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  18 | Time: 91.96s | Train Accuracy    0.861 | Train Loss    0.481 | Valid Accuracy    0.883 | Valid Loss    0.453 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |     5/   46 batches | accuracy    0.852\n",
            "| epoch  19 |    10/   46 batches | accuracy    0.858\n",
            "| epoch  19 |    15/   46 batches | accuracy    0.860\n",
            "| epoch  19 |    20/   46 batches | accuracy    0.859\n",
            "| epoch  19 |    25/   46 batches | accuracy    0.855\n",
            "| epoch  19 |    30/   46 batches | accuracy    0.854\n",
            "| epoch  19 |    35/   46 batches | accuracy    0.858\n",
            "| epoch  19 |    40/   46 batches | accuracy    0.860\n",
            "| epoch  19 |    45/   46 batches | accuracy    0.864\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  19 | Time: 91.14s | Train Accuracy    0.864 | Train Loss    0.475 | Valid Accuracy    0.882 | Valid Loss    0.443 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |     5/   46 batches | accuracy    0.875\n",
            "| epoch  20 |    10/   46 batches | accuracy    0.876\n",
            "| epoch  20 |    15/   46 batches | accuracy    0.868\n",
            "| epoch  20 |    20/   46 batches | accuracy    0.870\n",
            "| epoch  20 |    25/   46 batches | accuracy    0.868\n",
            "| epoch  20 |    30/   46 batches | accuracy    0.863\n",
            "| epoch  20 |    35/   46 batches | accuracy    0.867\n",
            "| epoch  20 |    40/   46 batches | accuracy    0.865\n",
            "| epoch  20 |    45/   46 batches | accuracy    0.870\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  20 | Time: 91.53s | Train Accuracy    0.870 | Train Loss    0.461 | Valid Accuracy    0.875 | Valid Loss    0.437 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |     5/   46 batches | accuracy    0.883\n",
            "| epoch  21 |    10/   46 batches | accuracy    0.874\n",
            "| epoch  21 |    15/   46 batches | accuracy    0.872\n",
            "| epoch  21 |    20/   46 batches | accuracy    0.874\n",
            "| epoch  21 |    25/   46 batches | accuracy    0.870\n",
            "| epoch  21 |    30/   46 batches | accuracy    0.871\n",
            "| epoch  21 |    35/   46 batches | accuracy    0.875\n",
            "| epoch  21 |    40/   46 batches | accuracy    0.873\n",
            "| epoch  21 |    45/   46 batches | accuracy    0.873\n",
            "-----------------------------------------------------------\n",
            "| End of epoch  21 | Time: 92.31s | Train Accuracy    0.873 | Train Loss    0.452 | Valid Accuracy    0.883 | Valid Loss    0.427 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |     5/   46 batches | accuracy    0.846\n",
            "| epoch  22 |    10/   46 batches | accuracy    0.862\n",
            "| epoch  22 |    15/   46 batches | accuracy    0.874\n",
            "| epoch  22 |    20/   46 batches | accuracy    0.863\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb Cell 53\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(save_model, exist_ok \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtransfer_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m transfer_model, transfer_metrics \u001b[39m=\u001b[39m train(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     transfer_model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n",
            "\u001b[1;32m/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb Cell 53\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_accs\u001b[39m.\u001b[39mappend(train_acc)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
            "\u001b[1;32m/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb Cell 53\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# backward\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/huydn/DATA/Learn/Practice_AI/deep_learning/6_pretrained_models_for_image/flower_classification_using_pretrained_model.ipynb#Y112sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "transfer_model = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")\n",
        "# freeze FE\n",
        "for param in transfer_model.parameters():\n",
        "   param.requires_grad = False\n",
        "\n",
        "in_features = transfer_model.fc.in_features\n",
        "transfer_model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transfer_model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(transfer_model.parameters(), lr=0.0001)\n",
        "\n",
        "num_epochs = 50\n",
        "save_model = 'model'\n",
        "os.makedirs(save_model, exist_ok = True)\n",
        "model_name = 'transfer_model'\n",
        "\n",
        "transfer_model, transfer_metrics = train(\n",
        "    transfer_model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqhT-xZ25v-0",
        "outputId": "691f38aa-9a6f-4e07-a542-393a936bb7db"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = evaluate_epoch(transfer_model, criterion, test_dataloader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "LItvSEP45zGX",
        "outputId": "28bc1527-7253-46be-d914-d551afaf4383"
      },
      "outputs": [],
      "source": [
        "plot_result(\n",
        "    num_epochs,\n",
        "    transfer_metrics[\"train_accuracy\"],\n",
        "    transfer_metrics[\"valid_accuracy\"],\n",
        "    transfer_metrics[\"train_loss\"],\n",
        "    transfer_metrics[\"valid_loss\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBBaFdjf4_dZ"
      },
      "source": [
        "###**4.3. Fine-Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb46HLR45Ff5",
        "outputId": "ec0cca01-2ac8-46b1-e30d-225feb0fb987"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQUYQMM7-pm4",
        "outputId": "bb884201-94bc-41db-a6c1-5364bae6293b"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeAgVXsN9aXX"
      },
      "outputs": [],
      "source": [
        "# freeze the first 50 layers\n",
        "num_layers = 50\n",
        "for index, param in enumerate(model.parameters()):\n",
        "    if index < num_layers:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd2fbr6cnv5y"
      },
      "outputs": [],
      "source": [
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTytQmmz_P6f",
        "outputId": "962fb16b-af78-4d40-d5a7-755811bceeb9"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8GvykIEn48Y"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENycynLnn5hk",
        "outputId": "e355daa3-861a-4a57-8d70-cf1ca0ba13f4"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up-SpW2R_SLc",
        "outputId": "028a9b8e-0d53-4ec2-86c1-55e2afda95a5"
      },
      "outputs": [],
      "source": [
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGuvvqBD_lC1",
        "outputId": "d656dee4-e9b4-4647-a823-7d8539c11f23"
      },
      "outputs": [],
      "source": [
        "fine_tuning_model = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "# freeze the first 50 layers\n",
        "num_layers = 50\n",
        "for index, param in enumerate(fine_tuning_model.parameters()):\n",
        "    if index < num_layers:\n",
        "        param.requires_grad = False\n",
        "\n",
        "in_features = fine_tuning_model.fc.in_features\n",
        "fine_tuning_model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "fine_tuning_model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fine_tuning_model.parameters(), lr=0.0001)\n",
        "\n",
        "num_epochs = 50\n",
        "save_model = 'model'\n",
        "os.makedirs(save_model, exist_ok = True)\n",
        "model_name = 'fine_tuning_model'\n",
        "\n",
        "fine_tuning_model, fine_tuning_metrics = train(\n",
        "    fine_tuning_model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Lduk5vEAvV",
        "outputId": "173bd3da-0a65-49e0-cece-6ec8d6a27b53"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = evaluate_epoch(fine_tuning_model, criterion, test_dataloader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Jd-ZqPzCEFJT",
        "outputId": "912f8396-e2cf-4b4d-8443-d677db11f61d"
      },
      "outputs": [],
      "source": [
        "plot_result(\n",
        "    num_epochs,\n",
        "    fine_tuning_metrics[\"train_accuracy\"],\n",
        "    fine_tuning_metrics[\"valid_accuracy\"],\n",
        "    fine_tuning_metrics[\"train_loss\"],\n",
        "    fine_tuning_metrics[\"valid_loss\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npiqGSQ_8dhA"
      },
      "source": [
        "###**4.4. Fine-Tuning (Initilization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a2vmUELKPvJ"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ2spOIpoxT7"
      },
      "outputs": [],
      "source": [
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqbiEV0NKSox",
        "outputId": "5cc7d647-01af-43f2-ca35-a63de4ec1988"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txHuQnaCKVVF",
        "outputId": "27a025de-0da3-455c-eae8-863cc05b3d4e"
      },
      "outputs": [],
      "source": [
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljT0xGr_Es1d",
        "outputId": "56788fe9-3fd1-4085-880b-c1d1c6ffc465"
      },
      "outputs": [],
      "source": [
        "initilization_model = models.resnet18(\n",
        "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
        "    )\n",
        "\n",
        "in_features = initilization_model.fc.in_features\n",
        "initilization_model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "initilization_model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(initilization_model.parameters(), lr=0.0001)\n",
        "\n",
        "num_epochs = 50\n",
        "save_model = 'model'\n",
        "os.makedirs(save_model, exist_ok = True)\n",
        "model_name = 'initilization_model'\n",
        "\n",
        "initilization_model, initilization_metrics = train(\n",
        "    initilization_model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpT4cIQTGvs4",
        "outputId": "4bec5ecd-51d7-4b05-ebb9-89629ee7eacb"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = evaluate_epoch(initilization_model, criterion, test_dataloader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "IjJmL9WDG0mU",
        "outputId": "8a98247c-a840-4bdd-b227-e939fbbcdeec"
      },
      "outputs": [],
      "source": [
        "plot_result(\n",
        "    num_epochs,\n",
        "    initilization_metrics[\"train_accuracy\"],\n",
        "    initilization_metrics[\"valid_accuracy\"],\n",
        "    initilization_metrics[\"train_loss\"],\n",
        "    initilization_metrics[\"valid_loss\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yVInf0s8mrf"
      },
      "source": [
        "##**5. Comparing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "wYs9j5w18qmT",
        "outputId": "527b28bd-908a-48b1-ddf2-c2be0b8439c5"
      },
      "outputs": [],
      "source": [
        "epochs = list(range(num_epochs))\n",
        "fig, axs = plt.subplots(nrows = 1, ncols =2 , figsize = (12,6))\n",
        "\n",
        "metrics = [base_metrics, transfer_metrics, fine_tuning_metrics, initilization_metrics]\n",
        "lables_plt = [\"base\", \"transfer_learning\", \"fine_tuning\", \"initilization\"]\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    axs[0].plot(epochs, metric['valid_loss'], label=lables_plt[idx])\n",
        "    axs[1].plot(epochs, metric['valid_accuracy'], label=lables_plt[idx])\n",
        "axs[0].set_xlabel(\"Epoch\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "axs[0].set_ylabel(\"Evaluation Loss\")\n",
        "axs[1].set_ylabel(\"Evaluation Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "GKIqz56fJyGn",
        "outputId": "5b588bc6-8fbd-474a-e97c-0e73a6ad4d48"
      },
      "outputs": [],
      "source": [
        "epochs = list(range(num_epochs))\n",
        "fig, axs = plt.subplots(nrows = 1, ncols =2 , figsize = (12,6))\n",
        "\n",
        "metrics = [base_metrics, transfer_metrics, fine_tuning_metrics, initilization_metrics]\n",
        "lables_plt = [\"base\", \"transfer_learning\", \"fine_tuning\", \"initilization\"]\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    axs[0].plot(epochs, metric['train_loss'], label=lables_plt[idx])\n",
        "    axs[1].plot(epochs, metric['train_accuracy'], label=lables_plt[idx])\n",
        "axs[0].set_xlabel(\"Epoch\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "axs[0].set_ylabel(\"Training Loss\")\n",
        "axs[1].set_ylabel(\"Training Accuracy\")\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
