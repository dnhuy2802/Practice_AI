{"cells":[{"cell_type":"markdown","metadata":{"id":"PDZxOtCZt5VU"},"source":["## Problem"]},{"cell_type":"markdown","metadata":{"id":"Z7esFCIXuNXS"},"source":["$$f(w_1, w_2) = 0.1w_1^2 + 2w_2^2 \\;\\;\\;\\;\\;\\;\\;(1)$$ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IAVg99F9N0y"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"HXAY82X82mDx"},"source":["### RMSprop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uai1hzbWuNaK"},"outputs":[],"source":["def df_w(W):\n","    \"\"\"\n","    Thực hiện tính gradient của dw1 và dw2\n","    Arguments:\n","    W -- np.array [w1, w2]\n","    Returns:\n","    dW -- np.array [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    \"\"\"\n","    #################### YOUR CODE HERE ####################\n","    \n","\n","    dW = np.array([0.1*2*W[0], 2*2*W[1]])\n","    ########################################################\n","    \n","    return dW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ws1QcU-o3NPi"},"outputs":[],"source":["def RMSProp(W, dW, lr, S, gamma):\n","    \"\"\"\n","    Thực hiện thuật tóan RMSProp để update w1 và w2\n","    Arguments:\n","    W -- np.array: [w1, w2]\n","    dW -- np.array: [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    lr -- float: learning rate \n","    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients\n","    gamma -- float: hệ số long-range average\n","    Returns:\n","    W -- np.array: [w1, w2] w1 và w2 sau khi đã update\n","    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients sau khi đã cập nhật\n","    \"\"\"\n","    epsilon = 1e-6\n","    #################### YOUR CODE HERE ####################\n","    \n","    S = gamma*S + (1-gamma)*dW**2\n","\n","    W = W - lr*dW/(np.sqrt(S)+epsilon)\n","    ########################################################\n","    return W, S"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QA_czueo4bz2"},"outputs":[],"source":["def train_p1(optimizer, lr, epochs):\n","    \"\"\"\n","    Thực hiện tìm điểm minimum của function (1) dựa vào thuật toán \n","    được truyền vào từ optimizer\n","    Arguments:\n","    optimize : function thực hiện thuật toán optimization cụ thể\n","    lr -- float: learning rate \n","    epochs -- int: số lượng lần (epoch) lặp để tìm điểm minimum \n","    Returns:\n","    results -- list: list các cặp điểm [w1, w2] sau mỗi epoch (mỗi lần cập nhật)\n","    \"\"\"\n","    # initial\n","    W = np.array([-5, -2], dtype=np.float32)\n","    S = np.array([0, 0], dtype=np.float32)\n","    results = [W]\n","    #################### YOUR CODE HERE ####################\n","    # Tạo vòng lặp theo số lần epochs\n","    # tìm gradient dW gồm dw1 và dw2\n","    # dùng thuật toán optimization cập nhật w1, w2, s1, s2\n","    # append cặp [w1, w2] vào list results\n","\n","    \n","    ########################################################\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGVlk8pi4kM5"},"outputs":[],"source":["train_p1(RMSProp, lr=0.3, epochs=30)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
